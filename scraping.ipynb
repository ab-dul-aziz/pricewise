{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import nest_asyncio\n",
    "import os\n",
    "\n",
    "import base64\n",
    "import json\n",
    "from time import perf_counter\n",
    "from typing import  Union\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "\n",
    "import html_text\n",
    "import nest_asyncio\n",
    "from multidict import CIMultiDict\n",
    "from openai import OpenAI\n",
    "from openai.types.chat.chat_completion import ChatCompletion\n",
    "from pydantic import BaseModel\n",
    "from w3lib.encoding import html_to_unicode, resolve_encoding\n",
    "from zyte_api import ZyteAPI\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve API keys from environment variables\n",
    "zyte_api_key = os.getenv('ZYTE_API_KEY')\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Initialize clients with the API keys\n",
    "client_zyte = ZyteAPI(api_key=zyte_api_key)\n",
    "client_openai = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# Additional configuration\n",
    "nest_asyncio.apply()\n",
    "model = \"gpt-3.5-turbo\"\n",
    "\n",
    "# Define temperature\n",
    "temperature = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Zyte API key\n",
    "client_zyte.get(\n",
    "  {\n",
    "    \"url\": \"https://www.rumah123.com/jual/cari/?q=rumah%20jabodetabek\",\n",
    "    \"httpResponseBody\": True,\n",
    "    \"httpResponseHeaders\": True,\n",
    "    \"product\": True,\n",
    "    \"productOptions\": {\n",
    "        \"extractFrom\": \"httpResponseBody\"\n",
    "    }\n",
    "  }\n",
    ")['statusCode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test OpenAI API key\n",
    "client_openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "      {\"role\": \"user\", \"content\": \"Hello\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    "  ).choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _auto_detect_encoding(body: bytes) -> Union[str, None]:\n",
    "    for encoding in [\"utf8\", \"cp1252\"]:\n",
    "        try:\n",
    "            body.decode(encoding)\n",
    "        except UnicodeError:\n",
    "            continue\n",
    "        return resolve_encoding(encoding)\n",
    "\n",
    "\n",
    "def _bytes_to_html(body: bytes, headers: list[dict]) -> str:\n",
    "    headers_dict = CIMultiDict([(h[\"name\"], h[\"value\"]) for h in headers])\n",
    "    content_type = headers_dict.get(\"Content-Type\")\n",
    "    _, html = html_to_unicode(\n",
    "        content_type,\n",
    "        body,\n",
    "        auto_detect_fun=_auto_detect_encoding,\n",
    "        default_encoding=\"utf8\",\n",
    "    )\n",
    "    return html\n",
    "\n",
    "\n",
    "def _get_html(web_page: dict):\n",
    "    try:\n",
    "        return web_page[\"html\"]\n",
    "    except KeyError:\n",
    "        body = base64.b64decode(web_page[\"httpResponseBody\"])\n",
    "        headers = web_page[\"httpResponseHeaders\"]\n",
    "        return _bytes_to_html(body, headers)\n",
    "\n",
    "\n",
    "def get_html_with_zapi(url: str, browser=False) -> Union[str, None]:\n",
    "  if browser:\n",
    "    web_page = client_zyte.get(\n",
    "      {\n",
    "        \"url\": url,\n",
    "        \"browserHtml\": True,\n",
    "      }\n",
    "    )\n",
    "    return web_page['browserHtml']\n",
    "  else:\n",
    "    web_page = client_zyte.get(\n",
    "      {\n",
    "        \"url\": url,\n",
    "        \"httpResponseBody\": True,\n",
    "        \"httpResponseHeaders\": True,\n",
    "      }\n",
    "    )\n",
    "\n",
    "    return _get_html(web_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities to extract using OpenAI API\n",
    "def extract_gpt_unstructured(text: str, data_to_extract: str) -> ChatCompletion:\n",
    "  \"\"\"\n",
    "  Extracts the data from `text` specified in plain text in `data_to_extract`.\n",
    "  \"\"\"\n",
    "  instruction = f\"\"\"\n",
    "Extract data from the following text or web page:\n",
    "\n",
    "[TEXT START]\n",
    "\n",
    "{text}\n",
    "\n",
    "[TEXT END]\n",
    "\n",
    "This is the data you must extract: {data_to_extract}\n",
    "\n",
    "Note: Some requested data might not be available. Specify it explicitly in that case.\n",
    "\"\"\".strip()\n",
    "\n",
    "  completion = client_openai.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "      {\"role\": \"user\", \"content\": instruction},\n",
    "    ],\n",
    "    temperature=temperature,\n",
    "  )\n",
    "\n",
    "  return completion\n",
    "\n",
    "\n",
    "def extract_gpt_structured_request_in_prompt(text: str, schema: dict) -> ChatCompletion:\n",
    "  \"\"\"\n",
    "  Extracts the data from `text` specified in as a json schema in `schema`.\n",
    "  Althought most of the time the extracted data will be parseable and schema-compliant, this method does not ensure so.\n",
    "  \"\"\"\n",
    "  instruction = f\"\"\"\n",
    "Extract data from the following text or web page:\n",
    "\n",
    "[TEXT START]\n",
    "\n",
    "{text}\n",
    "\n",
    "[TEXT END]\n",
    "\n",
    "Be sure to output only a json with the extraction.\n",
    "The json with extracted data must be compliant with this json schema:\n",
    "\n",
    "{json.dumps(schema, indent=4, ensure_ascii=False)}\n",
    "\n",
    "If there's any value you cannot find, set it as null in the extraction json.\n",
    "\"\"\".strip()\n",
    "\n",
    "  completion = client_openai.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "      {\"role\": \"user\", \"content\": instruction},\n",
    "    ],\n",
    "    temperature=temperature,\n",
    "  )\n",
    "\n",
    "  return completion\n",
    "\n",
    "\n",
    "def extract_gpt_structured(text: str, schema: BaseModel) -> ChatCompletion:\n",
    "  \"\"\"\n",
    "  Extracts the data from `text` specified in as a pydantic model in `schema`.\n",
    "  The response will always be parsable and schema-compliant.\n",
    "  \"\"\"\n",
    "  instruction = f\"\"\"\n",
    "Extract data from the following text or web page, according to the given schema.\n",
    "\n",
    "Here's the text from which you have to extract the data:\n",
    "\n",
    "[TEXT START]\n",
    "\n",
    "{text}\n",
    "\n",
    "[TEXT END]\n",
    "\n",
    "If there's any value you cannot find, set as null in the extraction json.\n",
    "\"\"\".strip()\n",
    "\n",
    "  completion = client_openai.beta.chat.completions.parse(\n",
    "      model=model,\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": instruction},\n",
    "      ],\n",
    "      temperature=temperature,\n",
    "      response_format=schema,\n",
    "  )\n",
    "\n",
    "  return completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List untuk menyimpan data properti\n",
    "property_links = []\n",
    "\n",
    "# Looping untuk beberapa halaman\n",
    "for current_page in range(1, 71):  # Mengambil data dari halaman 1 hingga 70, ubah range sesuai kebutuhan\n",
    "    page_url = f\"https://www.rumah123.com/jual/cari/?q=rumah+jabodetabek&page={current_page}\"\n",
    "    \n",
    "    # Mengunduh halaman menggunakan requests\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(page_url, headers=headers)\n",
    "    \n",
    "    # Periksa status response\n",
    "    if response.status_code == 200:\n",
    "        # Parse HTML menggunakan BeautifulSoup\n",
    "        page_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Loop untuk setiap properti pada halaman\n",
    "        for property_item in page_soup.find_all('div', {'class': 'card-featured__middle-section'}):\n",
    "            property_info = {}\n",
    "\n",
    "            # Mengambil title dan link dari tag <a>\n",
    "            link_tag = property_item.find('a', {'title': True})  # Tag <a> dengan atribut 'title'\n",
    "            if link_tag:\n",
    "                property_info['property_title'] = link_tag.get('title')  # Judul properti\n",
    "                property_info['property_url'] = link_tag.get('href')  # URL properti\n",
    "            \n",
    "            # Menyimpan data ke dalam list\n",
    "            property_links.append(property_info)\n",
    "\n",
    "        print(f\"Page {current_page} processed successfully.\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch page {current_page}. Status code: {response.status_code}\")\n",
    "\n",
    "    # Tidur sejenak sebelum melanjutkan ke halaman berikutnya\n",
    "    sleep(1)\n",
    "\n",
    "# Membuat dataframe dari list property_links\n",
    "properties_df = pd.DataFrame(property_links)\n",
    "\n",
    "# Simpan ke file CSV\n",
    "properties_df.to_csv('link_properties.csv', index=False)\n",
    "print(\"Data has been saved to properties.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Scraping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    /properti/jakarta-selatan/hos18392523/\n",
       "1      /properti/jakarta-utara/hos16808954/\n",
       "2              /properti/depok/hos18861745/\n",
       "3              /properti/depok/hos18570241/\n",
       "4      /properti/jakarta-utara/hos16543371/\n",
       "Name: property_url, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link123 = pd.read_csv('data/link_properties.csv')\n",
    "link123['property_url'][0: 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema outside of the loop as it doesn't change\n",
    "schema = {\n",
    "    \"title\": {\"type\": \"string\", \"description\": \"The title of the house\"},\n",
    "    \"description\": {\"type\": \"string\", \"description\": \"The description of the house\"},\n",
    "    \"price\": {\"type\": \"number\", \"description\": \"The price of the house\"},\n",
    "    \"address\": {\"type\": \"string\", \"description\": \"The address of the house\"},\n",
    "    \"city\": {\"type\": \"string\", \"description\": \"The city of the house\"},\n",
    "    \"land_size_m2\": {\"type\": \"number\", \"description\": \"The landsize (LT) without m2 of the house, if there is NaN fill 0\"},\n",
    "    \"building_size_m2\": {\"type\": \"number\", \"description\": \"The buildingsize (LB) without m2 of the house, if there is NaN fill 0\"},\n",
    "    \"bedroom\": {\"type\": \"number\", \"description\": \"The number of bedroom in the house, if there is NaN fill 0\"},\n",
    "    \"bathroom\": {\"type\": \"number\", \"description\": \"The number of bathroom in the house, if there is NaN fill 0\"},\n",
    "    \"garage\": {\"type\": \"number\", \"description\": \"The number of garage in the house, only the number and string that means number, if there is NaN fill 0\"},\n",
    "    \"carport\": {\"type\": \"number\", \"description\": \"The number of carport in the house if there is NaN fill 0\"},\n",
    "    \"property_type\": {\"type\": \"string\", \"description\": \"The type of the property, only if property_type = house\"},\n",
    "    \"certificate\": {\"type\": \"string\", \"description\": \"The certificate of the house, if there is Null fill Not Specified\"},\n",
    "    \"voltage_watt\": {\"type\": \"number\", \"description\": \"The voltage without watt of the house, if there is Null fill Not Specified\"},\n",
    "    \"maid_bedroom\": {\"type\": \"number\", \"description\": \"The number of maid bedroom in the house, if there is NaN fill 0\"},\n",
    "    \"maid_bathroom\": {\"type\": \"number\", \"description\": \"The number of maid bathroom in the house, if there is NaN fill 0\"},\n",
    "    \"kitchen\": {\"type\": \"number\", \"description\": \"The number of kitchen in the house, if there is NaN fill 0\"},\n",
    "    \"dining_room\": {\"type\": \"number\", \"description\": \"The number of dining room in the house, if there is NaN fill 0\"},\n",
    "    \"living_room\": {\"type\": \"number\", \"description\": \"The number of living room in the house, if there is NaN fill 0\"},\n",
    "    \"furniture\": {\"type\": \"string\", \"description\": \"The number of furniture in the house\", \"enum\": [\"Semi Furnished\", \"Furnished\", \"Unfurnished\"]},\n",
    "    \"building_material\": {\"type\": \"string\", \"description\": \"The number of building material in the house\"},\n",
    "    \"floor_material\": {\"type\": \"string\", \"description\": \"The number of building material in the house\"},\n",
    "    \"floor_level\": {\"type\": \"number\", \"description\": \"The number of floor level in the house, if there is NaN fill 0\"},\n",
    "    \"house_facing\": {\"type\": \"string\", \"description\": \"The number of face of the house\", \"enum\": [\"North\", \"South\", \"East\", \"West\", \"Southeast\", \"Southwest\", \"Northeast\", \"Northwest\"]},\n",
    "    \"concept_and_style\": {\"type\": \"string\", \"description\": \"The concept and style of the house\"},\n",
    "    \"view\": {\"type\": \"string\", \"description\": \"The view from the house\"},\n",
    "    \"internet_access\": {\"type\": \"string\", \"description\": \"Whether the house has internet access\"},\n",
    "    \"road_width\": {\"type\": \"string\", \"description\": \"The road width in front of the house\"},\n",
    "    \"year_built\": {\"type\": \"number\", \"description\": \"The year the house was built\"},\n",
    "    \"year_renovated\": {\"type\": \"number\", \"description\": \"The year the house was last renovated\"},\n",
    "    \"water_source\": {\"type\": \"string\", \"description\": \"The water source for the house\"},\n",
    "    \"corner_property\": {\"type\": \"boolean\", \"description\": \"Whether the house is a corner property (hook)\"},\n",
    "    \"property_condition\": {\"type\": \"string\", \"description\": \"The condition of the property\"},\n",
    "    \"ad_type\": {\"type\": \"string\", \"description\": \"The type of advertisement for the property\"},\n",
    "    \"ad_id\": {\"type\": \"string\", \"description\": \"The ID of the advertisement\"}\n",
    "}\n",
    "\n",
    "# Initialize container for valid JSON\n",
    "list_container = []\n",
    "\n",
    "# List of URLs to scrape\n",
    "property_urls = [\n",
    "    f\"https://www.rumah123.com{i}\" for i in link123['property_url'][0: 5]\n",
    "]\n",
    "\n",
    "# Loop through the property URLs to process each one\n",
    "for idx, url in enumerate(property_urls):\n",
    "    try:\n",
    "        print(f\"Processing index-{idx} with link {url}\")\n",
    "\n",
    "        # Extract HTML with ZAPI\n",
    "        html = get_html_with_zapi(url, browser=False)\n",
    "\n",
    "        # Extract plain text from the HTML\n",
    "        text = html_text.extract_text(html, guess_layout=True)\n",
    "\n",
    "        # Extract structured data from the text using the schema\n",
    "        completion = extract_gpt_structured_request_in_prompt(text=text, schema=schema)\n",
    "\n",
    "        # Retrieve and clean the content from the completion result\n",
    "        completion_text = completion.choices[0].message.content.strip()\n",
    "\n",
    "        # Append the cleaned content to the list\n",
    "        list_container.append(completion_text)\n",
    "\n",
    "        # Save progress to a temporary file every 5 iterations\n",
    "        if idx % 2 == 0 or idx == len(property_urls) - 1:\n",
    "            with open(\"temp_data.json\", \"w\") as f:\n",
    "                json.dump(list_container, f)\n",
    "            print(f\"Progress saved at index-{idx}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # Log errors\n",
    "        print(f\"Error processing index-{idx}: {e}\")\n",
    "\n",
    "    # Optional: Add delay to avoid server blocking\n",
    "    sleep(1)\n",
    "\n",
    "# Convert the list of strings to valid JSON and load them into a list\n",
    "valid_json = []\n",
    "for json_str in list_container:\n",
    "    try:\n",
    "        # Ensure proper JSON format (removing unwanted characters and handling malformed input)\n",
    "        clean_json = json_str.replace('`', '').replace(\"\\n\", \"\").replace('json', '')\n",
    "        valid_json.append(json.loads(clean_json))\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error decoding JSON: {json_str}\")\n",
    "\n",
    "# Convert the list of valid JSON into a DataFrame\n",
    "df = pd.DataFrame(valid_json)\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "df.to_csv('data_harga_rumah123.csv', index=False)\n",
    "print(\"Data has been saved to data_harga_rumah123.csv.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phase2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
